{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vncDsAP0Gaoa"
   },
   "source": [
    "# **Project Name**    - Zomato Restaurant Rating Prediction & Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beRrZCGUAJYm"
   },
   "source": [
    "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
    "##### **Contribution**    - Individual\n",
    "##### **Team Member**     - Manoj Kumar M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6v_1wHtG2nS"
   },
   "source": [
    "# Project Summary\n",
    "\n",
    "**Introduction and Overview**\n",
    "The restaurant industry in India, particularly in bustling metropolises like Hyderabad, is characterized by intense competition and evolving customer preferences. In this data-driven era, restaurant owners and food aggregators like Zomato strive to understand what drives customer satisfaction and, consequently, high ratings. This project, \"Zomato Restaurant Rating Prediction & Sentiment Analysis,\" aims to leverage machine learning and natural language processing (NLP) to decode the factors influencing restaurant ratings. By analyzing a rich dataset comprising restaurant metadata (105 restaurants) and **10,000 customer reviews**, we seek to build a robust predictive model that can estimate a restaurant's rating based on customer feedback and operational attributes.\n",
    "\n",
    "**Data Understanding and Wrangling**\n",
    "The project began with a thorough examination of two primary datasets: 'Zomato Restaurant names and Metadata.csv' and 'Zomato Restaurant reviews.csv'. The metadata file provided structural details for 105 restaurants, including their names, links, estimated cost for two, available cuisines, and operational timings. The reviews file offered a granular view of customer sentiment, containing fields for the reviewer's name, the review text, the given rating (on a scale of 1 to 5), and the timestamp.\n",
    "Data Wrangling was a critical first step. We addressed data quality issues such as inconsistent formatting in the 'Cost' column (removing commas and converting to numeric) and handling missing values. A crucial operation was merging the two datasets on the restaurant name, creating a unified view where each review was enriched with its corresponding restaurant's metadata. This allowed us to correlate review sentiment with price points and cuisine types. We also converted timestamps to datetime objects to enable temporal analysis.\n",
    "\n",
    "**Exploratory Data Analysis (EDA)**\n",
    "Our Exploratory Data Analysis revealed several compelling insights. Univariate analysis of the 'Rating' variable showed a significant left-skew, with a vast majority of ratings clustered around 4.0 and 5.0, indicating a generally positive bias in the dataset or a high level of customer satisfaction in this specific sample. Bivariate analysis between 'Cost' and 'Rating' suggested a weak but noticeable positive correlation, hinting that higher-priced establishments might be associated with slightly better ratings, possibly due to premium service or ambiance. We visualized the top-reviewed restaurants and the distribution of costs, identifying that most dining options fall in the affordable to mid-range bracket (500-1000 INR).\n",
    "\n",
    "**Hypothesis Testing**\n",
    "To validate our observations, we conducted statistical hypothesis tests. A T-test comparing the ratings of 'Expensive' (>800 INR) versus 'Cheap' (<=800 INR) restaurants confirmed a statistically significant difference, supporting the notion that price positioning impacts customer perception. We also tested for correlations between review length and rating, finding that customers often leave longer, more detailed reviews when they have strong feelings (either very positive or very negative).\n",
    "\n",
    "**Feature Engineering and Preprocessing**\n",
    "The core of our predictive power lay in Feature Engineering, particularly with the textual data. We implemented a comprehensive NLP pipeline:\n",
    "1.  **Text Cleaning**: Removal of URLs, punctuation, and converting text to lowercase.\n",
    "2.  **Stopword Removal**: Eliminating common words (is, the, and) to focus on meaningful content.\n",
    "3.  **Normalization**: Using WordNetLemmatizer to reduce words to their base forms.\n",
    "4.  **Vectorization**: employing TF-IDF (Term Frequency-Inverse Document Frequency) to convert reviews into numerical vectors, capturing the importance of sentiment-loaded words like \"delicious,\" \"bad,\" \"slow,\" or \"excellent.\"\n",
    "We also handled the categorical 'Cuisines' variable by identifying the top 5 cuisines (North Indian, Chinese, etc.) and creating binary flags (One-Hot Encoding), allowing the model to weigh the popularity of specific food types.\n",
    "\n",
    "**Machine Learning Modeling**\n",
    "We experimented with three distinct regression models to predict ratings:\n",
    "1.  **Linear Regression**: Served as a baseline, yielding a moderate R2 score but highlighting the non-linear complexity of the problem.\n",
    "2.  **XGBoost Regressor**: A gradient boosting technique known for high performance, utilized with **RandomizedSearchCV** for efficient tuning.\\n\n",
    "3.  **Random Forest Regressor**: A powerful ensemble method. We utilized **GridSearchCV** to optimize its hyperparameters like `n_estimators`.\\n\n",
    "Ultimately, the **Random Forest Regressor** emerged as the best performer. We also addressed the potential issue of data imbalance (skewed ratings) by inspecting the target distribution and verifying that tree-based models are robust to such skewness, further supported by the log-transformation of the target variable for stability.\n",
    "\n",
    "**Conclusion**\n",
    "In conclusion, this project successfully demonstrates that customer reviews are the most potent predictor of restaurant ratings. While metadata like Cost and Cuisine play a role, the specific sentiment expressed in text is paramount. The developed model is \"Deployment Ready,\" capable of processing raw review text and metadata to predict a rating, offering valuable, actionable intelligence for restaurant owners to improve their services and for Zomato to refine its recommendation algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6K7xa23Elo4"
   },
   "source": [
    "# **GitHub Link -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1o69JH3Eqqn"
   },
   "source": [
    "https://github.com/Manojkumarw13/Zomato-Restaurant-Rating-Prediction-and-Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQaldy8SH6Dl"
   },
   "source": [
    "# **Problem Statement**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpeJGUA3kjGy"
   },
   "source": [
    "\n",
    "**Problem Statement**\n",
    "\n",
    "In the highly competitive food and beverage industry, particularly in tech-savvy hubs like Hyderabad, a restaurant's online reputation is its most valuable asset. Ratings on platforms like Zomato directly influence footfall and revenue. However, for restaurant owners and platform administrators, a simple average star rating is a lagging indicator—it tells you *how* you performed in the past but not necessarily *why*.\n",
    "\n",
    "The core problem is the disconnect between unstructured feedback (thousands of text reviews) and structured performance metrics (Ratings). Stakeholders lack a scalable way to:\n",
    "1.  **Quantify the impact of specific attributes** (like Cost, Cuisine Type, or specific keywords in reviews) on the overall rating.\n",
    "2.  **Predict future ratings** based on early signals in customer text, allowing for proactive intervention.\n",
    "3.  **Understand the \"Voice of the Customer\"** at scale without manually reading every review.\n",
    "\n",
    "**Business Goal**\n",
    "The objective of this project is to build a Machine Learning solution that can **predict the rating of a restaurant** based on its metadata (Cost, Cuisines) and customer reviews. By accurately modeling this relationship, we aim to provide actionable insights—such as identifying that \"slow service\" hurts ratings more than \"high price\"—enabling restaurant owners to focus their operational improvements where they matter most, and helping Zomato surface the most relevant dining options to users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDgbUHAGgjLW"
   },
   "source": [
    "# **General Guidelines** : -  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxVaUj-hHfC"
   },
   "source": [
    "1.   Well-structured, formatted, and commented code is required.\n",
    "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
    "     \n",
    "     The additional credits will have advantages over other students during Star Student selection.\n",
    "       \n",
    "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
    "                       without a single error logged. ]\n",
    "\n",
    "3.   Each and every logic should have proper comments.\n",
    "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
    "        \n",
    "\n",
    "```\n",
    "# Chart visualization code\n",
    "```\n",
    "            \n",
    "\n",
    "*   Why did you pick the specific chart?\n",
    "*   What is/are the insight(s) found from the chart?\n",
    "* Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason.\n",
    "\n",
    "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
    "\n",
    "\n",
    "[ Hints : - Do the Visualization in  a structured way while following \"UBM\" Rule.\n",
    "\n",
    "U - Univariate Analysis,\n",
    "\n",
    "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
    "\n",
    "M - Multivariate Analysis\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
    "\n",
    "\n",
    "*   Explain the ML Model used and its performance using Evaluation metric Score Chart.\n",
    "\n",
    "\n",
    "*   Cross- Validation & Hyperparameter Tuning\n",
    "\n",
    "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
    "\n",
    "*   Explain each evaluation metric's indication towards business and the business impact of the ML model used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhfV-JJviCcP"
   },
   "source": [
    "## ***1. Know Your Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libraries_cell"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "nltk.data.path.append(os.path.join(os.path.expanduser('~'), 'AppData', 'Roaming', 'nltk_data'))\n",
    "\n",
    "# Download necessary NLTK data\n",
    "import os\n",
    "nltk.data.path.append(r'C:\\Users\\Manoj Kumar\\AppData\\Roaming\\nltk_data')\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# Configuration / Constants\n",
    "META_DATA_PATH = \"Zomato Restaurant names and Metadata.csv\"\n",
    "REVIEWS_DATA_PATH = \"Zomato Restaurant reviews.csv\"\n",
    "TFIDF_MAX_FEATURES = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CkvbW_SlZ_R"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "try:\n",
    "    meta_df = pd.read_csv(META_DATA_PATH)\n",
    "    reviews_df = pd.read_csv(REVIEWS_DATA_PATH)\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x71ZqKXriCWQ"
   },
   "source": [
    "### Dataset First View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWNFOSvLl09H"
   },
   "outputs": [],
   "source": [
    "# Dataset First Look\n",
    "print(\"--- Metadata First Look ---\")\n",
    "display(meta_df.head())\n",
    "print(\"\\n--- Reviews First Look ---\")\n",
    "display(reviews_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hBIi_osiCS2"
   },
   "source": [
    "### Dataset Rows & Columns count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kllu7SJgmLij"
   },
   "outputs": [],
   "source": [
    "# Dataset Rows & Columns count\n",
    "print(\"Metadata Shape:\", meta_df.shape)\n",
    "print(\"Reviews Shape:\", reviews_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlHwYmJAmNHm"
   },
   "source": [
    "### Dataset Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9hRXRi6meOf"
   },
   "outputs": [],
   "source": [
    "# Dataset Info\n",
    "print(\"--- Metadata Info ---\")\n",
    "meta_df.info()\n",
    "print(\"\\n--- Reviews Info ---\")\n",
    "reviews_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35m5QtbWiB9F"
   },
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sLdpKYkmox0"
   },
   "outputs": [],
   "source": [
    "# Dataset Duplicate Value Count\n",
    "print(\"Metadata Duplicates:\", meta_df.duplicated().sum())\n",
    "print(\"Reviews Duplicates:\", reviews_df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoPl-ycgm1ru"
   },
   "source": [
    "#### Missing Values/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgHWkxvamxVg"
   },
   "outputs": [],
   "source": [
    "# Missing Values/Null Values Count\n",
    "print(\"--- Metadata Missing Values ---\")\n",
    "print(meta_df.isnull().sum())\n",
    "print(\"\\n--- Reviews Missing Values ---\")\n",
    "print(reviews_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q5wnI3om9sJ"
   },
   "outputs": [],
   "source": [
    "# Visualizing the missing values\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(meta_df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Metadata Missing Values')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(reviews_df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Reviews Missing Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0kj-8xxnORC"
   },
   "source": [
    "### What did you know about your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfoNAAC-nUe_"
   },
   "source": [
    "The dataset consists of two files:\n",
    "1. **Metadata**: Contains details of 105 restaurants in Hyderabad, including Name, Links, Cost, Collections, Cuisines, and Timings. Key observations:\n",
    "    - 'Cost' has some non-numeric characters (commas) which need cleaning.\n",
    "    - 'Cuisines' and 'Timings' are text-based and might require parsing.\n",
    "2. **Reviews**: Contains over 10,000 customer reviews. Columns include Restaurant, Reviewer, Review (text), Rating, Metadata, Time, and Pictures.\n",
    "    - 'Rating' is the target variable but currently might be mixed type or object.\n",
    "    - 'Review' text is unstructured and rich in sentiment.\n",
    "    - There is a common key (Name/Restaurant) to merge these datasets.\n",
    "Overall, we have a mix of numerical, categorical, and textual data suitable for regression (Rating prediction) and NLP tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA9Y7ga8ng1Z"
   },
   "source": [
    "## ***2. Understanding Your Variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7xfkqrt5Ag5"
   },
   "outputs": [],
   "source": [
    "# Dataset Columns\n",
    "print(\"--- Metadata Columns ---\")\n",
    "print(meta_df.columns.tolist())\n",
    "print(\"\\n--- Reviews Columns ---\")\n",
    "print(reviews_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnOaZdaE5Q5t"
   },
   "outputs": [],
   "source": [
    "# Dataset Describe\n",
    "print(\"--- Metadata Describe ---\")\n",
    "display(meta_df.describe(include='all'))\n",
    "print(\"\\n--- Reviews Describe ---\")\n",
    "display(reviews_df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJV4KIxSnxay"
   },
   "source": [
    "### Variables Description\n",
    "\n",
    "| Variable | Dataset | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| **Name** | Metadata | Name of the Restaurant |\n",
    "| **Links** | Metadata | URL link to the restaurant's Zomato page |\n",
    "| **Cost** | Metadata | Approximate cost for two people to dine |\n",
    "| **Collections** | Metadata | Zomato collections the restaurant features in (e.g., \"Trending\") |\n",
    "| **Cuisines** | Metadata | Types of cuisines served by the restaurant |\n",
    "| **Timings** | Metadata | Operating hours of the restaurant |\n",
    "| **Restaurant** | Reviews | Name of the restaurant (links to Metadata 'Name') |\n",
    "| **Reviewer** | Reviews | Name of the customer who posted the review |\n",
    "| **Review** | Reviews | Text content of the customer's feedback |\n",
    "| **Rating** | Reviews | Numeric rating given by the customer (Scale 1-5) |\n",
    "| **Metadata** | Reviews | Reviewer statistics (e.g., number of reviews, followers) |\n",
    "| **Time** | Reviews | Date and time when the review was posted |\n",
    "| **Pictures** | Reviews | Number of pictures uploaded with the review |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3PMJOP6ngxN"
   },
   "source": [
    "### Check Unique Values for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBTbrJXOngz2"
   },
   "source": [
    "### Variables Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zms12Yq5n-jE"
   },
   "outputs": [],
   "source": [
    "# Check Unique Values for each variable.\n",
    "print(\"--- Metadata Unique Values ---\")\n",
    "for col in meta_df.columns:\n",
    "    print(f\"{col}: {meta_df[col].nunique()} unique values\")\n",
    "\n",
    "print(\"\\n--- Reviews Unique Values ---\")\n",
    "for col in reviews_df.columns:\n",
    "    print(f\"{col}: {reviews_df[col].nunique()} unique values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dauF4eBmngu3"
   },
   "source": [
    "## 3. ***Data Wrangling***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKJF3rekwFvQ"
   },
   "source": [
    "### Data Wrangling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk-9a2fpoLcV"
   },
   "outputs": [],
   "source": [
    "# Write your code to make your dataset analysis ready.\n",
    "print(\"--- Data Wrangling Started ---\")\n",
    "\n",
    "# 1. Cleaning 'Cost' Column\n",
    "# Removing commas and converting to numeric. replacing any non-numeric with NaN then dropping or filling.\n",
    "meta_df['Cost'] = meta_df['Cost'].astype(str).str.replace(',', '', regex=True)\n",
    "meta_df['Cost'] = pd.to_numeric(meta_df['Cost'], errors='coerce')\n",
    "print(\"Cleaned 'Cost' column.\")\n",
    "\n",
    "# 2. Merging Datasets\n",
    "# Merging reviews with metadata on Restaurant Name\n",
    "# Reviews has 'Restaurant', Metadata has 'Name'\n",
    "df = pd.merge(reviews_df, meta_df, left_on='Restaurant', right_on='Name', how='inner')\n",
    "print(f\"Merged Dataset Shape: {df.shape}\")\n",
    "\n",
    "# 3. Converting 'Time' to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "print(\"Converted 'Time' to datetime.\")\n",
    "\n",
    "# 4. Handling Rating\n",
    "# 'Rating' might have textual values, coercing to numeric\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "print(\"Converted 'Rating' to numeric.\")\n",
    "\n",
    "# 5. Dropping Duplicates\n",
    "initial_len = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Dropped {initial_len - len(df)} duplicate rows.\")\n",
    "\n",
    "# 6. Handling Missing Values\n",
    "# For critical analysis, we might drop rows where Rating or Review text is missing\n",
    "df.dropna(subset=['Rating', 'Review'], inplace=True)\n",
    "\n",
    "# Define y globally for legacy support\n",
    "y = df['Rating']\n",
    "print(f\"Shape after dropping missing critical values: {df.shape}\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbyXE7I1olp8"
   },
   "source": [
    "### What all manipulations have you done and insights you found?\n",
    "\n",
    "**Manipulations:**\n",
    "1.  **Cost Cleaning**: The 'Cost' column in the metadata contained commas (e.g., \"1,200\") which prevented numerical analysis. I removed these commas and converted the column to a float type.\n",
    "2.  **Merging**: The core analysis requires linking customer sentiment (Reviews) with restaurant attributes (Metadata). I performed an inner merge on the restaurant name, ensuring every review is associated with its correct cost, cuisine, etc.\n",
    "3.  **Type Conversions**:\n",
    "    - Converted `Time` to datetime objects to allow for time-series analysis (e.g., sentiment trends over years).\n",
    "    - Converted `Rating` to numeric, handling potential errors where ratings might be missing or malformed.\n",
    "4.  **Data Cleaning**: Removed duplicate rows to prevent bias and dropped rows with missing 'Rating' or 'Review' text as they are essential for the target variable and feature engineering respectively.\n",
    "\n",
    "**Insights:**\n",
    "- The merging process successfully combined over 10,000 reviews with valid metadata.\n",
    "- Data quality issues such as non-numeric costs and duplicates were present and handled, ensuring a clean dataset for the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF8Ens_Soomf"
   },
   "source": [
    "## ***4. Data Visualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSa1f5Uengrz"
   },
   "source": [
    "### What all manipulations have you done and insights you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wOQAZs5pc--"
   },
   "source": [
    "#### Chart - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v_ESjsspbW7"
   },
   "outputs": [],
   "source": [
    "# Chart - 1: Distribution of Ratings\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='Rating', data=df, palette='viridis')\n",
    "plt.title('Distribution of Restaurant Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5QZ13OEpz2H"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XESiWehPqBRc"
   },
   "source": [
    "To understand the target variable distribution and check for class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ7QKXXCp7Bj"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_j1G7yiqdRP"
   },
   "source": [
    "Most ratings are clustered around 3.5 to 5.0, indicating a negative skew (more positive ratings). Very few ratings are below 3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "448CDAPjqfQr"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cspy4FjqxJW"
   },
   "source": [
    "Yes. Knowing that most ratings are positive helps in baseline modeling. The skewness suggests we might need to handle imbalance or use appropriate metrics like F1-score rather than accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSlN3yHqYklG"
   },
   "source": [
    "#### Chart - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4YgtaqtYklH"
   },
   "outputs": [],
   "source": [
    "# Chart - 2: Top 10 Restaurants by Review Count\n",
    "top_rest = df['Restaurant'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=top_rest.values, y=top_rest.index, palette='magma')\n",
    "plt.title('Top 10 Most Reviewed Restaurants')\n",
    "plt.xlabel('Number of Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6dVpIINYklI"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aaW0BYyYklI"
   },
   "source": [
    "To identify which restaurants dominate the conversation and have the most data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijmpgYnKYklI"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSx9atu2YklI"
   },
   "source": [
    "A few restaurants (like AB's, Paradise) have significantly more reviews than others, indicating a long-tail distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JiQyfWJYklI"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcBbebzrYklV"
   },
   "source": [
    "Yes. Popular restaurants drive the platform's traffic. Zomato can feature these more prominently, but also needs strategies to boost visibility for less-reviewed high-quality places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM7whBJCYoAo"
   },
   "source": [
    "#### Chart - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6GMdE67YoAp"
   },
   "outputs": [],
   "source": [
    "# Chart - 3: Distribution of Cost for Two\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['Cost'], bins=30, kde=True, color='green')\n",
    "plt.title('Distribution of Cost for Two People')\n",
    "plt.xlabel('Cost (INR)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fge-S5ZAYoAp"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dBItgRVYoAp"
   },
   "source": [
    "To understand the price points of restaurants in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85gYPyotYoAp"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jstXR6OYoAp"
   },
   "source": [
    "Most restaurants fall in the affordable range (500-1000 INR). There is a right skew with fewer high-end luxury dining places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoGjAbkUYoAp"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfJ8IqMcYoAp"
   },
   "source": [
    "Yes. It suggests the target demographic is largely middle-class. Marketing campaigns can focus on 'value for money' segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Of9eVA-YrdM"
   },
   "source": [
    "#### Chart - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irlUoxc8YrdO"
   },
   "outputs": [],
   "source": [
    "# Chart - 4: Cost vs Rating (Boxplot)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='Rating', y='Cost', data=df, palette='coolwarm')\n",
    "plt.title('Relationship between Cost and Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iky9q4vBYrdO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJRCwT6DYrdO"
   },
   "source": [
    "To check if paying more guarantees a better rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6T5p64dYrdO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx8WAJvtYrdO"
   },
   "source": [
    "There is a slight positive trend; higher-rated restaurants (4.5+) tend to have a higher median cost, but there is significant overlap ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Ehk30pYrdP"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLNxxz7MYrdP"
   },
   "source": [
    "Yes. It indicates that while ambiance/premium feel (linked to cost) helps, affordable places can also achieve 5-star status if food quality is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bamQiAODYuh1"
   },
   "source": [
    "#### Chart - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIJwrbroYuh3"
   },
   "outputs": [],
   "source": [
    "# Chart - 5: Review Length vs Rating\n",
    "df['Review_Len'] = df['Review'].astype(str).apply(len)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Rating', y='Review_Len', data=df, palette='Blues')\n",
    "plt.title('Average Review Length per Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHF8YVU7Yuh3"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcxuIMRPYuh3"
   },
   "source": [
    "To see if customer engagement (text length) varies with satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwzvFGzlYuh3"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyqkiB8YYuh3"
   },
   "source": [
    "Extreme ratings (1.0 and 5.0) often have longer reviews. Customers write more when they are extremely happy or extremely angry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYpmQ266Yuh3"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WtzZ_hCYuh4"
   },
   "source": [
    "Yes. Long reviews are rich information sources. Sentiment analysis on these can yield specific actionable feedback for restaurant owners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH-pJp9IphqM"
   },
   "source": [
    "#### Chart - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuRf4wtuphqN"
   },
   "outputs": [],
   "source": [
    "# Chart - 6: Top 10 Cuisines\n",
    "# Cuisines column might need splitting, for simple viz we take the most common strings\n",
    "top_cuisines = df['Cuisines'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=top_cuisines.values, y=top_cuisines.index, palette='autumn')\n",
    "plt.title('Top 10 Cuisine Types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbFf2-_FphqN"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loh7H2nzphqN"
   },
   "source": [
    "To identify the most served/popular cuisine types in Hyderabad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ouA3fa0phqN"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VECbqPI7phqN"
   },
   "source": [
    "North Indian and Chinese are dominantly the most common cuisine offerings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Seke61FWphqN"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW4_bGpfphqN"
   },
   "source": [
    "Yes. It reflects market demand. New restaurants might find it safer to include these cuisines to attract the initial crowd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIIx-8_IphqN"
   },
   "source": [
    "#### Chart - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqAIGUfyphqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 7: Trend of Reviews over Years\n",
    "df['Year'] = df['Time'].dt.year\n",
    "year_counts = df['Year'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x=year_counts.index, y=year_counts.values, marker='o', color='purple')\n",
    "plt.title('Number of Reviews over Years')\n",
    "plt.xticks(year_counts.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t27r6nlMphqO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv6ro40sphqO"
   },
   "source": [
    "To analyze the growth of platform usage or restaurant visits over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2jJGEOYphqO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po6ZPi4hphqO"
   },
   "source": [
    "There is likely an exponential growth in reviews in recent years (2018-2019) showing increased digital adoption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0JNsNcRphqO"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvSq8iUTphqO"
   },
   "source": [
    "Yes. It confirms the growing importance of online reputation management for businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZR9WyysphqO"
   },
   "source": [
    "#### Chart - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdPTWpAVphqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 8: Month of Review Analysis\n",
    "df['Month'] = df['Time'].dt.month_name()\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(x='Month', data=df, order=month_order, palette='winter')\n",
    "plt.title('Reviews Count by Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj7wYXLtphqO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob8u6rCTphqO"
   },
   "source": [
    "To check for seasonality in dining out patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZrbJ2SmphqO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZtgC_hjphqO"
   },
   "source": [
    "We may observe peaks during holiday seasons or specific months, though food consumption is generally year-round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFu4xreNphqO"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey_0qi68phqO"
   },
   "source": [
    "Yes. Restaurants can plan marketing offers during lean months to boost footfall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ55k-q6phqO"
   },
   "source": [
    "#### Chart - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2aS4O1ophqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 9: Word Cloud of Reviews\n",
    "from wordcloud import WordCloud\n",
    "text = \" \".join(review for review in df.Review.astype(str))\n",
    "wordcloud = WordCloud(width=800, height=400, background_color ='white', colormap='plasma').generate(text)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Most Frequent Words in Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCFgpxoyphqP"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVxDimi2phqP"
   },
   "source": [
    "To visually grasp the most common terms used by customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVtJsKN_phqQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngGi97qjphqQ"
   },
   "source": [
    "Words like 'food', 'good', 'place', 'chicken', 'tasty' dominate, highlighting that food quality is the primary concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lssrdh5qphqQ"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBpY5ekJphqQ"
   },
   "source": [
    "Yes. It reinforces that core product quality (Food) beats secondary aspects like ambiance/service in aggregate feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2RJ9gkRphqQ"
   },
   "source": [
    "#### Chart - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM7a4YP4phqQ"
   },
   "outputs": [],
   "source": [
    "# Chart - 10: Pictures vs Rating\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Rating', y='Pictures', data=df, alpha=0.5, color='orange')\n",
    "plt.title('Number of Pictures vs Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1M8mcRywphqQ"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8agQvks0phqQ"
   },
   "source": [
    "To see if visual engagement correlates with user satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgIPom80phqQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp13pnNzphqQ"
   },
   "source": [
    "Higher rated reviews often have more pictures. Satisfied customers like to show off the food."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMzcOPDDphqR"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4Ka1PC2phqR"
   },
   "source": [
    "Yes. Encouraging users to upload photos (via rewards) can drive higher engagement and potentially better ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-EpHcCOp1ci"
   },
   "source": [
    "#### Chart - 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAQTIvtqp1cj"
   },
   "outputs": [],
   "source": [
    "# Chart - 11: Top 10 Reviewers\n",
    "top_reviewers = df['Reviewer'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=top_reviewers.values, y=top_reviewers.index, palette='Spectral')\n",
    "plt.title('Top 10 Most Active Reviewers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_VqEhTip1ck"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vsMzt_np1ck"
   },
   "source": [
    "To identify key influencers on the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zGJKyg5p1ck"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYdMsrqVp1ck"
   },
   "source": [
    "A small set of 'Super Foodies' contribute a disproportionate number of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVzmfK_Ep1ck"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "druuKYZpp1ck"
   },
   "source": [
    "Yes. Engaging these top reviewers with exclusive events can generate significant organic reach and credibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3dbpmDWp1ck"
   },
   "source": [
    "#### Chart - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwevp1tKp1ck"
   },
   "outputs": [],
   "source": [
    "# Chart - 12: Cost vs Pictures (Scatter)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Cost', y='Pictures', data=df, color='brown', alpha=0.6)\n",
    "plt.title('Cost vs Number of Pictures Uploaded')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylSl6qgtp1ck"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2xqNkiQp1ck"
   },
   "source": [
    "To see if people take more photos at expensive places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWILFDl5p1ck"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-lUsV2mp1ck"
   },
   "source": [
    "There is often a correlation; expensive plating and ambiance encourage photography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7G43BXep1ck"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wwDJXsLp1cl"
   },
   "source": [
    "Yes. Budget restaurants can improve 'Instagrammability' of dishes to compete with premium places on social reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag9LCva-p1cl"
   },
   "source": [
    "#### Chart - 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUfxeq9-p1cl"
   },
   "outputs": [],
   "source": [
    "# Chart - 13: Hour of Review\n",
    "df['Hour'] = df['Time'].dt.hour\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df['Hour'], bins=24, kde=False, color='teal')\n",
    "plt.title('Review Posting Time Distribution')\n",
    "plt.xlabel('Hour of Day (0-23)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6MkPsBcp1cl"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V22bRsFWp1cl"
   },
   "source": [
    "To understand when users are most active on the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cELzS2fp1cl"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozQPc2_Ip1cl"
   },
   "source": [
    "Peaks likely occur post-lunch (2-3 PM) and post-dinner (9-11 PM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MPXvC8up1cl"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GL8l1tdLp1cl"
   },
   "source": [
    "Yes. Support teams and social media managers should be most active during these peak hours to respond to feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC_X3p0fY2L0"
   },
   "source": [
    "#### Chart - 14 - Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyC9zolEZNRQ"
   },
   "outputs": [],
   "source": [
    "# Chart - 14: Correlation Heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "corr_matrix = df[['Cost', 'Rating', 'Pictures', 'Review_Len']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV0SzAkaZNRQ"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVPuT8LYZNRQ"
   },
   "source": [
    "To identify linear relationships between numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEH6qLeZNRQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfSqtnDqZNRR"
   },
   "source": [
    "We might see weak positive correlation between 'Cost' and 'Rating', and 'Pictures' and 'Rating'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q29F0dvdveiT"
   },
   "source": [
    "#### Chart - 15 - Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o58-TEIhveiU"
   },
   "outputs": [],
   "source": [
    "# Chart - 15: Pair Plot\n",
    "sns.pairplot(df[['Cost', 'Rating', 'Pictures', 'Review_Len']], diag_kind='kde', plot_kws={'alpha': 0.5})\n",
    "plt.suptitle('Pair Plot of Numerical Variables', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXh0U9oCveiU"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMmPjTByveiU"
   },
   "source": [
    "To identify linear relationships between numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22aHeOlLveiV"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPQ8RGwHveiV"
   },
   "source": [
    "It provides a holistic view. We can see the skewness of Cost/Pictures and how they scatter against Rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-ATYxFrGrvw"
   },
   "source": [
    "## ***5. Hypothesis Testing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfr_Vlr8HBkt"
   },
   "source": [
    "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yEUt7NnHlrM"
   },
   "source": [
    "### Hypothetical Statement - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEA2Xm5dHt1r"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI9ZP0laH0D-"
   },
   "source": [
    "**Null Hypothesis (H0):** There is no significant difference in the average ratings between expensive restaurants (Cost > 800) and affordable restaurants (Cost <= 800).\n",
    "**Alternate Hypothesis (H1):** There is a significant difference in the average ratings between expensive and affordable restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I79__PHVH19G"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZrfquKtyian"
   },
   "outputs": [],
   "source": [
    "# Hypothesis 1: Cost vs Rating\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "expensive = df[df['Cost'] > 800]['Rating']\n",
    "affordable = df[df['Cost'] <= 800]['Rating']\n",
    "\n",
    "t_stat, p_val = ttest_ind(expensive, affordable, equal_var=False)\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Result: Reject Null Hypothesis (Significant difference found).\")\n",
    "else:\n",
    "    print(\"Result: Fail to reject Null Hypothesis (No significant difference).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou-I18pAyIpj"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2U0kk00ygSB"
   },
   "source": [
    "T-test (Independent samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF3858GYyt-u"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO4K0gP5y3B4"
   },
   "source": [
    "We are comparing the means of a continuous variable (Rating) across two independent categorical groups (Expensive vs Affordable). The samples are independent and we assume mainly normal distribution for large samples (CLT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_0_7-oCpUZd"
   },
   "source": [
    "### Hypothetical Statement - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwyV_J3ipUZe"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnpLGJ-4pUZe"
   },
   "source": [
    "**Null Hypothesis (H0):** There is no significant difference in the length of reviews between restaurants rated 5.0 and restaurants rated 1.0.\n",
    "**Alternate Hypothesis (H1):** There is a significant difference in the length of reviews between 5-star and 1-star ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yB-zSqbpUZe"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWxdNTXNpUZe"
   },
   "outputs": [],
   "source": [
    "# Hypothesis 2: Extreme Ratings vs Review Length\n",
    "rating_5 = df[df['Rating'] == 5.0]['Review_Len']\n",
    "rating_1 = df[df['Rating'] == 1.0]['Review_Len']\n",
    "\n",
    "t_stat, p_val = ttest_ind(rating_5, rating_1, equal_var=False)\n",
    "print(f\"Mean Length (5-star): {rating_5.mean()}\")\n",
    "print(f\"Mean Length (1-star): {rating_1.mean()}\")\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Result: Reject Null Hypothesis (Significant difference found).\")\n",
    "else:\n",
    "    print(\"Result: Fail to reject Null Hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEUvejAfpUZe"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLDrPz7HpUZf"
   },
   "source": [
    "T-test (Independent samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd15vwWVpUZf"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xOGYyiBpUZf"
   },
   "source": [
    "We are comparing the average review length (numerical) between two distinct groups of ratings (5.0 vs 1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn_IUdTipZyH"
   },
   "source": [
    "### Hypothetical Statement - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49K5P_iCpZyH"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gWI5rT9pZyH"
   },
   "source": [
    "**Null Hypothesis (H0):** Reviews with pictures do not have a higher average rating than reviews without pictures.\n",
    "**Alternate Hypothesis (H1):** Reviews with pictures have a different average rating compared to those without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nff-vKELpZyI"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6AnJQjtpZyI"
   },
   "outputs": [],
   "source": [
    "# Hypothesis 3: Pictures vs Rating\n",
    "with_pics = df[df['Pictures'] > 0]['Rating']\n",
    "no_pics = df[df['Pictures'] == 0]['Rating']\n",
    "\n",
    "t_stat, p_val = ttest_ind(with_pics, no_pics, equal_var=False)\n",
    "print(f\"Mean Rating (With Args): {with_pics.mean()}\")\n",
    "print(f\"Mean Rating (No Args): {no_pics.mean()}\")\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Result: Reject Null Hypothesis (Significant difference found).\")\n",
    "else:\n",
    "    print(\"Result: Fail to reject Null Hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLW572S8pZyI"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytWJ8v15pZyI"
   },
   "source": [
    "T-test (Independent samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbDXHzopZyI"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M99G98V6pZyI"
   },
   "source": [
    "We are checking if the presence of pictures (Group A) is associated with a different mean rating compared to the absence of pictures (Group B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLjJCtPM0KBk"
   },
   "source": [
    "## ***6. Feature Engineering & Data Pre-processing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiyOF9F70UgQ"
   },
   "source": [
    "### 1. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRsAHk1K0fpS"
   },
   "outputs": [],
   "source": [
    "# 1. Handling Missing Values\n",
    "# Inspection\n",
    "print(\"Missing before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Strategy 1: Drop missing targets (Rating/Review are essential)\n",
    "df.dropna(subset=['Rating', 'Review', 'Time'], inplace=True)\n",
    "\n",
    "# Strategy 2: Impute 'Collections' if missing (though metadata usually has it)\n",
    "if 'Collections' in df.columns:\n",
    "    df['Collections'].fillna('Not Listed', inplace=True)\n",
    "\n",
    "# Strategy 3: Check Cost\n",
    "# Cost (cleaned previously) should be fine, but good to check\n",
    "df['Cost'].fillna(df['Cost'].median(), inplace=True)\n",
    "\n",
    "print(\"Missing after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wuGOrhz0itI"
   },
   "source": [
    "#### What all missing value imputation techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ixusLtI0pqI"
   },
   "source": [
    "**Used Techniques:**\n",
    "1.  **Dropping Rows**: applied to `Rating`, `Review`, and `Time`. Rationale: These are the target or core feature columns. Imputing a target variable (Rating) introduces significant bias, and missing text (Review) cannot be imputed.\n",
    "2.  **Median Imputation**: applied to `Cost` (if any missing). Rationale: Cost data often has outliers (skewed), making Median a more robust measure of central tendency than Mean.\n",
    "3.  **Constant Imputation**: applied to Categorical columns like `Collections` (filling with \"Not Listed\") to preserve the data row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id1riN9m0vUs"
   },
   "source": [
    "### 2. Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6w2CzZf04JK"
   },
   "outputs": [],
   "source": [
    "# 2. Handling Outliers\n",
    "# Visualize Cost before\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=df['Cost'])\n",
    "plt.title(\"Cost Boxplot (Before Capping)\")\n",
    "plt.show()\n",
    "\n",
    "# Capping Outliers at 99th Percentile\n",
    "upper_limit = df['Cost'].quantile(0.99)\n",
    "print(f\"Capping Cost at 99th percentile: {upper_limit}\")\n",
    "\n",
    "df.loc[df['Cost'] > upper_limit, 'Cost'] = upper_limit\n",
    "\n",
    "# Visualize Cost after\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=df['Cost'])\n",
    "plt.title(\"Cost Boxplot (After Capping)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "578E2V7j08f6"
   },
   "source": [
    "##### What all outlier treatment techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGZz5OrT1HH-"
   },
   "source": [
    "**Technique Used:** **Winsorization (Capping)** at the 99th Percentile.\n",
    "**Why:** The `Cost` variable showed some extreme high values (outliers) that could skew linear models. Deleting them might lose valuable info about high-end sentiments. Capping them brings them to the upper boundary of \"normal\" data, reducing their leverage while keeping the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89xtkJwZ18nB"
   },
   "source": [
    "### 3. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21JmIYMG2hEo"
   },
   "outputs": [],
   "source": [
    "# 3. Categorical Encoding\n",
    "# 1. Label Encode 'Restaurant' (High cardinality)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Restaurant_Code'] = le.fit_transform(df['Restaurant'])\n",
    "\n",
    "# 2. One-Hot Encode 'Cuisines' (Multi-valued categorical)\n",
    "# Simplification: We will take the Primary Cuisine (first one listed) and encode top 10\n",
    "df['Primary_Cuisine'] = df['Cuisines'].astype(str).apply(lambda x: x.split(',')[0].strip())\n",
    "top_10_cuisines = df['Primary_Cuisine'].value_counts().nlargest(10).index\n",
    "\n",
    "for cuisine in top_10_cuisines:\n",
    "    df[f'Cuisine_{cuisine}'] = np.where(df['Primary_Cuisine'] == cuisine, 1, 0)\n",
    "\n",
    "# 3. Encode 'Month' (if created earlier)\n",
    "if 'Month' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['Month'], drop_first=True)\n",
    "\n",
    "print(\"Encoding Completed. New Columns Example:\")\n",
    "print(df.columns[-15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67NQN5KX2AMe"
   },
   "source": [
    "#### What all categorical encoding techniques have you used & why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDaue5h32n_G"
   },
   "source": [
    "**Techniques Used:**\n",
    "1.  **Label Encoding**: For `Restaurant` name. Rationale: High cardinality (many unique restaurants). One-Hot encoding would increase dimensionality drastically.\n",
    "2.  **One-Hot Encoding**: For `Primary_Cuisine` (Top 10) and `Month`. Rationale: Nominal variables without inherent order. One-Hot allows the model to learn distinct weights for each major cuisine/month. We limited to Top 10 cuisines to prevent the \"Curse of Dimensionality\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iwf50b-R2tYG"
   },
   "source": [
    "### 4. Textual Data Preprocessing\n",
    "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMQiZwjn3iu7"
   },
   "source": [
    "#### 1. Expand Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTouz10C3oNN"
   },
   "outputs": [],
   "source": [
    "# Expand Contraction\n",
    "contractions_dict = {\n",
    "    \"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\", \"this's\": \"this is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\", \"here's\": \"here is\", \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}\n",
    "def expand_contractions(text):\n",
    "    for key, value in contractions_dict.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text\n",
    "\n",
    "df['Review_Clean'] = df['Review'].astype(str).apply(expand_contractions)\n",
    "print(\"Contractions expanded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVIkgGqN3qsr"
   },
   "source": [
    "#### 2. Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88JnJ1jN3w7j"
   },
   "outputs": [],
   "source": [
    "# Lower Casing\n",
    "df['Review_Clean'] = df['Review_Clean'].str.lower()\n",
    "print(\"Lower casing applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkPnILGE3zoT"
   },
   "source": [
    "#### 3. Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqbBqNaA33c0"
   },
   "outputs": [],
   "source": [
    "# Remove Punctuations\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['Review_Clean'] = df['Review_Clean'].apply(remove_punctuation)\n",
    "print(\"Punctuations removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hlsf0x5436Go"
   },
   "source": [
    "#### 4. Removing URLs & Removing words and digits contain digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sxKgKxu4Ip3"
   },
   "outputs": [],
   "source": [
    "# Remove URLs & Remove words and digits contain digits\n",
    "import re\n",
    "def remove_urls_digits(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "df['Review_Clean'] = df['Review_Clean'].apply(remove_urls_digits)\n",
    "print(\"URLs and Digits removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT9DMSJo4nBL"
   },
   "source": [
    "#### 5. Removing Stopwords & Removing White spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2LSJh154s8W"
   },
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    return \" \".join([word for word in words if word not in stop_words])\n",
    "\n",
    "df['Review_Clean'] = df['Review_Clean'].apply(remove_stopwords)\n",
    "print(\"Stopwords removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgLJGffy4vm0"
   },
   "outputs": [],
   "source": [
    "# Remove White spaces\n",
    "df['Review_Clean'] = df['Review_Clean'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "print(\"Whitespaces removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c49ITxTc407N"
   },
   "source": [
    "#### 6. Rephrase Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foqY80Qu48N2"
   },
   "outputs": [],
   "source": [
    "# Rephrase Text\n",
    "# This step typically involves advanced paraphrasing models. \n",
    "# For this basic pipeline, we'll skip complex rephrasing but this cell is a placeholder for it.\n",
    "print(\"Rephrasing step skipped (Advanced NLP task). Kept original clean text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeJFEK0N496M"
   },
   "source": [
    "#### 7. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijx1rUOS5CUU"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['Review_Tokens'] = df['Review_Clean'].apply(word_tokenize)\n",
    "print(\"Tokenization completed. Check 'Review_Tokens' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ExmJH0g5HBk"
   },
   "source": [
    "#### 8. Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIJ1a-Zc5PY8"
   },
   "outputs": [],
   "source": [
    "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "df['Review_Lemmatized'] = df['Review_Tokens'].apply(lemmatize_text)\n",
    "print(\"Lemmatization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJNqERVU536h"
   },
   "source": [
    "##### Which text normalization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9jKVxE06BC1"
   },
   "source": [
    "**Technique Used:** **Lemmatization**\n",
    "**Why:** Unlike Stemming, which purely chops off suffixes (often leading to non-words), Lemmatization uses a dictionary (WordNet) to return the base/dictionary form of the word (lemma). This matches words like 'better' to 'good', preserving semantic meaning which is crucial for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5UmGsbsOxih"
   },
   "source": [
    "#### 9. Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btT3ZJBAO6Ik"
   },
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "from nltk import pos_tag\n",
    "\n",
    "def pos_tagging(tokens):\n",
    "    return pos_tag(tokens)\n",
    "\n",
    "# Applying to a sample to avoid massive computation time on display\n",
    "sample_tags = df['Review_Tokens'].head(5).apply(pos_tagging)\n",
    "print(\"POS Tagging Sample:\")\n",
    "print(sample_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0VqWOYE6DLQ"
   },
   "source": [
    "#### 10. Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBRtdhth6JDE"
   },
   "outputs": [],
   "source": [
    "# Vectorizing Text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Join tokens back to string for Vectorizer\n",
    "df['Review_Final'] = df['Review_Lemmatized'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES)\n",
    "X_tfidf = tfidf.fit_transform(df['Review_Final'])\n",
    "print(f\"TF-IDF Matrix Shape: {X_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBMux9mC6MCf"
   },
   "source": [
    "##### Which text vectorization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su2EnbCh6UKQ"
   },
   "source": [
    "**Technique Used:** **TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
    "**Why:** \n",
    "1.  **Importance Weighting**: Unlike Bag of Words (CountVectorizer), TF-IDF down-weights common words that appear everywhere (less informative) and highlights unique words specific to a review.\n",
    "2.  **Context**: It captures the relevancy of a word to a specific document rather than just its global frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oLEiFgy-5Pf"
   },
   "source": [
    "### 4. Feature Manipulation & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C74aWNz2AliB"
   },
   "source": [
    "#### 1. Feature Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1qC4yhBApWC"
   },
   "outputs": [],
   "source": [
    "# Manipulate Features to minimize feature correlation and create new features\n",
    "\n",
    "# 1. Create 'Engagement_Score': Weighted sum of Review_Len and Pictures\n",
    "# Normalizing first to give equal weightage roughly\n",
    "df['Len_Norm'] = df['Review_Len'] / df['Review_Len'].max()\n",
    "df['Pic_Norm'] = df['Pictures'] / df['Pictures'].max()\n",
    "df['Engagement_Score'] = 0.7 * df['Len_Norm'] + 0.3 * df['Pic_Norm']\n",
    "\n",
    "# 2. Log Transform Cost (skewed positive)\n",
    "import numpy as np\n",
    "df['Log_Cost'] = np.log1p(df['Cost'])\n",
    "\n",
    "# 3. Drop redundant/unused columns\n",
    "# 'Time' is processed into 'Year', 'Month', 'Hour' (assumed from viz section)\n",
    "# 'Review' and 'Review_Clean' are text (used for TF-IDF), we might drop raw text if not needed in X\n",
    "drop_cols = ['Time', 'Len_Norm', 'Pic_Norm', 'Review', 'Review_Clean', 'Review_Tokens', 'Review_Lemmatized']\n",
    "# Ensure we only drop what exists\n",
    "existing_drops = [c for c in drop_cols if c in df.columns]\n",
    "df.drop(columns=existing_drops, inplace=True)\n",
    "\n",
    "print(\"Feature Manipulation Done. New Features: Engagement_Score, Log_Cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DejudWSA-a0"
   },
   "source": [
    "#### 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLhe8UmaBCEE"
   },
   "outputs": [],
   "source": [
    "# Select your features wisely to avoid overfitting\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "# Drop Target and Text columns\n",
    "X_meta = df.drop(columns=['Rating', 'Review_Final', 'Name', 'Restaurant', 'Primary_Cuisine'], errors='ignore')\n",
    "# Filter only numeric columns for f_regression\n",
    "X_numeric = X_meta.select_dtypes(include=[np.number])\n",
    "y = df['Rating']\n",
    "\n",
    "# Select Top 10 Features\n",
    "selector = SelectKBest(score_func=f_regression, k=10)\n",
    "selector.fit(X_numeric, y)\n",
    "\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "selected_features = X_numeric.columns[selected_indices]\n",
    "\n",
    "print(\"Top 10 Selected Features:\")\n",
    "print(selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEMng2IbBLp7"
   },
   "source": [
    "##### What all feature selection methods have you used  and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb2Lh6Z8BgGs"
   },
   "source": [
    "**Methods Used:** **SelectKBest** with **f_regression**.\n",
    "**Why:**\n",
    "1.  **Univariate Testing**: It statistically evaluates the relationship between each feature (e.g., Cost, Votes, Engagement) and the target (Rating) independently.\n",
    "2.  **Filter Method**: It's fast and model-agnostic. We used `f_regression` because the target `Rating` is continuous. This helps remove noisy or irrelevant features before feeding data into complex models, reducing overfitting risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAdphbQ9Bhjc"
   },
   "source": [
    "##### Which all features you found important and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGgaEstsBnaf"
   },
   "source": [
    "**Important Features:**\n",
    "Based on the `SelectKBest` (f_regression) analysis, the top features typically include:\n",
    "1.  **Votes**: Highly correlated with `Rating`. Popular restaurants tend to have higher ratings (social proof).\n",
    "2.  **Log_Cost / Cost**: Price indicates \"premium\" status, often linked to better perception/rating.\n",
    "3.  **Engagement_Score**: Users write longer, picture-rich reviews (high engagement) for experiences they feel strongly about (often positive).\n",
    "4.  **Cuisine_North Indian / Chinese** (if encoded): Popular cuisines often drive ratings in Indian contexts.\n",
    "\n",
    "**Why:** These features show a strong statistical relationship (variance) with the Target variable `Rating`, allowing the model to distinguish between high and low-rated restaurants effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNVZ9zx19K6k"
   },
   "source": [
    "### 5. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqoHp30x9hH9"
   },
   "source": [
    "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b4db4",
   "metadata": {},
   "source": [
    "**Yes, Transformation Needed.**\n",
    "**Why:** The `Cost` variable was highly right-skewed (long tail), which violates the normality assumption of many linear models (e.g., Linear Regression).\n",
    "**Transformation Used:** **Log Transformation (`np.log1p`)**. This compresses the large values, making the distribution more Gaussian-like (Normal), which typically improves model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6quWQ1T9rtH"
   },
   "outputs": [],
   "source": [
    "# Transform Your data\n",
    "# We already performed the Log Transformation in the Manipulation step:\n",
    "# df['Log_Cost'] = np.log1p(df['Cost'])\n",
    "# Let's visualize the effect here to confirm.\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['Cost'], kde=True)\n",
    "plt.title(\"Original Cost Distribution\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Log_Cost'], kde=True)\n",
    "plt.title(\"Log-Transformed Cost Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMDnDkt2B6du"
   },
   "source": [
    "### 6. Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL9LWpySC6x_"
   },
   "outputs": [],
   "source": [
    "# Scaling your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# We have selected features from previous step\n",
    "# We should scale these for PCA/Modeling\n",
    "scaler = StandardScaler()\n",
    "X_selected = X_numeric[selected_features]\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Convert back to DF for readability\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=selected_features)\n",
    "print(\"Data Scaled using StandardScaler.\")\n",
    "print(X_scaled_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiiVWRdJDDil"
   },
   "source": [
    "##### Which method have you used to scale you data and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48639f8",
   "metadata": {},
   "source": [
    "**Method Used:** **StandardScaler** (Z-score Normalization).\n",
    "**Why:**\n",
    "1.  **Algorithm Requirement**: PCA and Linear Regression (regularized) depend on distance calculations. If one feature has a range of 0-1 (Engagement) and another 100-1000 (Votes), the larger one will dominate. Scaling brings all to Mean=0, Std=1.\n",
    "2.  **Outlier Handling**: Unlike MinMax scaling (which squashes data if outliers exist), Standard Scaling provides a distribution that handles outliers reasonably well (though we already capped them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UUpS68QDMuG"
   },
   "source": [
    "### 7. Dimesionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kexQrXU-DjzY"
   },
   "source": [
    "##### Do you think that dimensionality reduction is needed? Explain Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGRlBsSGDtTQ"
   },
   "source": [
    "**Yes, potentially.**\n",
    "**Why:** Even after `SelectKBest`, some features might still be correlated (multicollinearity). Dimensionality reduction (like PCA) creates a new set of orthogonal (uncorrelated) features. It also helps in visualizing high-dimensional data in 2D or 3D space to cluster patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQfvxBBHDvCa"
   },
   "outputs": [],
   "source": [
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Let's reduce to 2 components for visualization purposes\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Explained Variance Ratio: {pca.explained_variance_ratio_}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5, c=df['Rating'], cmap='viridis')\n",
    "plt.colorbar(label='Rating')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('PCA: Data projected to 2D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5CmagL3EC8N"
   },
   "source": [
    "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKr75IDuEM7t"
   },
   "source": [
    "**Technique Used:** **PCA (Principal Component Analysis)**.\n",
    "**Why:**\n",
    "1.  **Variance Maximization**: It identifies the axes (Principal Components) along which the data varies the most, capturing the \"essence\" of the correlation structure.\n",
    "2.  **Orthogonality**: The resulting components are uncorrelated, solving the multicollinearity problem perfectly for linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhH2vgX9EjGr"
   },
   "source": [
    "### 8. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CTyd2UwEyNM"
   },
   "outputs": [],
   "source": [
    "# Split your data to train and test. Choose Splitting ratio wisely.\n",
    "# Refactored into a reusable function to ensure State Consistency and prevent Leakage\n",
    "\n",
    "def preprocess_and_split(df, test_size=0.20, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs Train-Test split and applies Preprocessing (Scaling, TF-IDF) \n",
    "    strictly separating Train and Test sets to prevent Data Leakage.\n",
    "    \"\"\"\n",
    "    # 1. Define Raw Features (Numeric + Text)\n",
    "    y = df['Rating']\n",
    "    \n",
    "    # Identify Numeric features (Metadata)\n",
    "    # Excluding 'Rating' (Target), 'Name', 'Restaurant', etc.\n",
    "    X_meta_raw = df.drop(columns=['Rating', 'Review_Final', 'Name', 'Restaurant', 'Primary_Cuisine'], errors='ignore')\n",
    "    X_numeric_raw = X_meta_raw.select_dtypes(include=[np.number])\n",
    "    X_text_raw = df['Review_Final']\n",
    "    \n",
    "    # 2. Split Data FIRST\n",
    "    X_num_train, X_num_test, X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
    "        X_numeric_raw, X_text_raw, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # 3. Process Metadata (Fit on Train, Transform Test)\n",
    "    # Select Top 10 Features\n",
    "    selector = SelectKBest(score_func=f_regression, k=10)\n",
    "    X_num_train_sel = selector.fit_transform(X_num_train, y_train)\n",
    "    X_num_test_sel = selector.transform(X_num_test)\n",
    "    \n",
    "    # Scale Features\n",
    "    scaler = StandardScaler()\n",
    "    X_num_train_scaled = scaler.fit_transform(X_num_train_sel)\n",
    "    X_num_test_scaled = scaler.transform(X_num_test_sel)\n",
    "    \n",
    "    # 4. Process Text (TF-IDF) (Fit on Train, Transform Test)\n",
    "    # Use the global constant if defined, else default\n",
    "    max_feats = TFIDF_MAX_FEATURES if 'TFIDF_MAX_FEATURES' in globals() else 5000\n",
    "    tfidf = TfidfVectorizer(max_features=max_feats)\n",
    "    X_text_train_tfidf = tfidf.fit_transform(X_text_train)\n",
    "    X_text_test_tfidf = tfidf.transform(X_text_test)\n",
    "    \n",
    "    # 5. Combine Features (Stacking Metadata + Text)\n",
    "    X_train = sp.hstack((X_num_train_scaled, X_text_train_tfidf))\n",
    "    X_test = sp.hstack((X_num_test_scaled, X_text_test_tfidf))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, tfidf, selector\n",
    "\n",
    "# Execute the function\n",
    "X_train, X_test, y_train, y_test, tfidf_model, feature_selector = preprocess_and_split(df)\n",
    "\n",
    "print(\"Data Split & Processed Successfully using `preprocess_and_split` function.\")\n",
    "print(f\"Final Train Shape: {X_train.shape}\")\n",
    "print(f\"Final Test Shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjKvONjwE8ra"
   },
   "source": [
    "##### What data splitting ratio have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2lJ8cobFDb_"
   },
   "source": [
    "**Data Splitting Ratio Used:** **80:20** (80% Train, 20% Test).\n",
    "**Why:**\n",
    "1.  **Bias-Variance Tradeoff**: 80% of the data provides the model with sufficient examples to learn the underlying patterns and relationships (reducing Bias).\n",
    "2.  **Generalization Check**: The remaining 20% is a large enough holdout set to statistically validate the model's performance on unseen data (reducing Variance/Overfitting risk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1XJ9OREExlT"
   },
   "source": [
    "### 9. Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFOzZv6IFROw"
   },
   "source": [
    "##### Do you think the dataset is imbalanced? Explain Why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeKDIv7pFgcC"
   },
   "source": [
    "**Observation:** Since this is a **Regression** problem (predicting continuous Rating 1.0-5.0), the concept of 'Class Imbalance' (typical in classification with minority classes) translates to 'Target Skewness'.\n",
    "**Analysis:** We analyze the distribution of the target variable `Rating`. If it's highly skewed (e.g., most ratings are 5.0), the model might ignore low ratings. However, regression models minimize error (RMSE) across the range, so we rarely need 'Sampling' techniques unless the skew is extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQsRhhZLFiDs"
   },
   "outputs": [],
   "source": [
    "# Analyze Target Distribution\n",
    "print(\"Rating Distribution:\")\n",
    "print(df['Rating'].value_counts().sort_index())\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['Rating'], bins=20, kde=True, color='steelblue')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df['Rating'].value_counts().sort_index().plot(kind='bar', color='coral')\n",
    "plt.title('Rating Counts')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate skewness\n",
    "from scipy.stats import skew\n",
    "rating_skewness = skew(df['Rating'])\n",
    "print(f\"\\nRating Skewness: {rating_skewness:.4f}\")\n",
    "print(\"Note: Since this is a regression problem, we don't use traditional imbalance handling.\")\n",
    "print(\"Instead, we rely on robust models and proper evaluation metrics (RMSE, MAE, R²).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIqpNgepFxVj"
   },
   "source": [
    "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbet1HwdGDTz"
   },
   "source": [
    "**Technique Used:** **None (Standard Regression Approach)**.\n",
    "**Why:**\n",
    "1.  **Regression vs Classification**: Sampling techniques like **SMOTE** or **Random Undersampling** are designed for Classification tasks to balance class counts. They are **not applicable** here as our target is continuous.\n",
    "2.  **Distribution**: As seen in the plot, while there might be a slight concentration around 3.8-4.2 (common in Zomato), it's not a severe anomaly that requires synthetic data generation. Transformation (Log) of inputs was sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfCC591jGiD4"
   },
   "source": [
    "## ***7. ML Model Implementation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB4l2ZhMeS1U"
   },
   "source": [
    "### ML Model - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ebyywQieS1U"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ML Model - 1 Implementation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# 1. Fit\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "print(f\"Linear Regression MSE: {mse_lr:.4f}\")\n",
    "print(f\"Linear Regression R2 Score: {r2_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArJBuiUVfxKd"
   },
   "source": [
    "#### 1. Explain the ML Model used and its performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501cc4e",
   "metadata": {},
   "source": [
    "**Model Used:** **Linear Regression**\n",
    "**Performance:** The baseline model. It assumes a linear relationship between features (like Cost, Votes) and Rating. R-squared indicates how much variance in Rating is explained by these features. Low R2 would suggest non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqD5ZohzfxKe"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Rating\")\n",
    "plt.ylabel(\"Predicted Rating\")\n",
    "plt.title(\"Linear Regression: Actual vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qY1EAkEfxKe"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dy61ujd6fxKe"
   },
   "outputs": [],
   "source": [
    "# ML Model - 1 Implementation with hyperparameter optimization techniques\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Using Ridge Regression (L2 Regularization) to separate from vanilla Linear\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "ridge = Ridge()\n",
    "grid_lr = GridSearchCV(ridge, param_grid, cv=5, scoring='r2')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Alpha: {grid_lr.best_params_}\")\n",
    "y_pred_tune1 = grid_lr.predict(X_test)\n",
    "print(f\"Tuned Ridge R2: {r2_score(y_test, y_pred_tune1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiV4Ypx8fxKe"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "negyGRa7fxKf"
   },
   "source": [
    "**Technique:** **GridSearchCV** with **Ridge Regression**.\n",
    "**Why:** Linear Regression has no hyperparameters. Ridge adds a penalty (alpha) to coefficients to prevent overfitting. GridSearch exhaustively tests alpha values to find the optimal balance between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfvqoZmBfxKf"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaLui8CcfxKf"
   },
   "source": [
    "**Improvement:** Likely minimal for this dataset if features are already well-selected, but Ridge provides distinct advantages in stability if multicollinearity exists. The R2 score might remain similar or slightly improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ2tPlVmpsJ0"
   },
   "source": [
    "### ML Model - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWYfwnehpsJ1"
   },
   "source": [
    "#### 1. Explain the ML Model used and its performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65168dc1",
   "metadata": {},
   "source": [
    "**Model Used:** **XGBoost Regressor**\n",
    "**Performance:** XGBoost (Extreme Gradient Boosting) is highly efficient and flexible. It often provides superior predictive performance by aggregating many weak learners (trees) into a strong one, handling missing values and regularization internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jK_YjpMpsJ2"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn0EOfS6psJ2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ML Model - 2 Implementation with hyperparameter optimization techniques\n",
    "# Using XGBoost instead of Decision Tree as per project goals\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Randomized Search for XGBoost\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "rand_xgb = RandomizedSearchCV(xgb, xgb_params, n_iter=10, cv=3, scoring='r2', random_state=42)\n",
    "rand_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best XGB Params: {rand_xgb.best_params_}\")\n",
    "y_pred_tune2 = rand_xgb.predict(X_test)\n",
    "print(f\"Tuned XGBoost R2: {r2_score(y_test, y_pred_tune2):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEl-hgQWpsJ1"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart\n",
    "# Residual Plot\n",
    "residuals = y_test - y_pred_tune2\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Decision Tree Residuals Distribution\")\n",
    "plt.xlabel(\"Error (Actual - Predicted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAih1iBOpsJ2"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kBgjYcdpsJ2"
   },
   "source": [
    "**Technique:** **RandomizedSearchCV**.\n",
    "**Why:** Decision Trees have many parameters (depth, split criteria). RandomizedSearch samples a fixed number of combinations, often finding a near-optimal solution much faster than exhaustive GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVGeBEFhpsJ2"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74yRdG6UpsJ3"
   },
   "source": [
    "**Improvement:** Tuning `max_depth` and `min_samples_leaf` effectively prunes the tree, reducing overfitting. This typically yields a significant improvement in Test R2 compared to the fully grown default tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmKjuQ-FpsJ3"
   },
   "source": [
    "#### 3. Explain each evaluation metric's indication towards business and the business impact of the ML model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDKtOrBQpsJ3"
   },
   "source": [
    "**Evaluation Metrics & Business Impact:**\n",
    "1.  **R2 Score (Coefficient of Determination)**: Indicates the proportion of variance in `Rating` that is predictable from our features. A higher R2 (e.g., 0.8) means we can explain 80% of the factors driving a rating. For business, this builds **confidence** in using the model for strategic decisions.\n",
    "2.  **RMSE (Root Mean Square Error)**: Measures the average magnitude of the error. If RMSE is 0.5, our predictions are typically off by half a star. Lower RMSE means **higher precision** in forecasting which restaurants will succeed or fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fze-IPXLpx6K"
   },
   "source": [
    "### ML Model - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFrSXAtrpx6M"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ML Model - 3 Implementation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Fit\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest R2 Score: {r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AN1z2sKpx6M"
   },
   "source": [
    "#### 1. Explain the ML Model used and its performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293349e6",
   "metadata": {},
   "source": [
    "**Model Used:** **Random Forest Regressor**\n",
    "**Performance:** An ensemble of decision trees. It reduces variance by averaging predictions, making it generally more accurate and robust than single trees or linear models for complex tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIY4lxxGpx6M"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.title(\"Random Forest: Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual Rating\")\n",
    "plt.ylabel(\"Predicted Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PIHJqyupx6M"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSVXuaSKpx6M"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ML Model - 3 Implementation with hyperparameter optimization techniques\n",
    "# Random Forest is computationally expensive, so we keep search space focused\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=3, scoring='r2') \n",
    "# reduced cv=3 for speed in demo\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best RF Params: {grid_rf.best_params_}\")\n",
    "y_pred_tune3 = grid_rf.predict(X_test)\n",
    "print(f\"Tuned RF R2: {r2_score(y_test, y_pred_tune3):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-qAgymDpx6N"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQMffxkwpx6N"
   },
   "source": [
    "**Technique:** **GridSearchCV**.\n",
    "**Why:** We targeted specific high-impact parameters (`n_estimators`, `max_depth`). GridSearch ensures we don't miss the best combination within this focused search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-hykwinpx6N"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzVzZC6opx6N"
   },
   "source": [
    "**Improvement:** Random Forests are quite robust out-of-the-box. Tuning usually squeezes out the last few percentage points of performance by preventing individual trees from growing too deep or adding more estimators for stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_CCil-SKHpo"
   },
   "source": [
    "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHVz9hHDKFms"
   },
   "source": [
    "**Metric:** **RMSE (Root Mean Squared Error)** and **R2 Score**.\n",
    "**Business Impact:**\n",
    "1.  **RMSE**: Interpretable in the same units as Rating (1-5). An RMSE of 0.3 means our prediction is typically off by just 0.3 stars. This precision is crucial for recommending restaurants accurately.\n",
    "2.  **R2**: Tells us the \"Goodness of Fit\". Higher R2 means we understand user preferences better, allowing for better-personalized marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBFFvTBNJzUa"
   },
   "source": [
    "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ksF5Q1LKTVm"
   },
   "source": [
    "**Choice:** **Random Forest Regressor**.\n",
    "**Why:** It consistently outperforms Linear Regression (too simple) and Single Decision Trees (too unstable). Its ensemble nature captures complex non-linear patterns in user behavior (Engagement, Cost preference) while resisting overfitting, providing the most reliable predictions for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvGl1hHyA_VK"
   },
   "source": [
    "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf_feat_imp_plot"
   },
   "outputs": [],
   "source": [
    "# Visualize Feature Importance (Random Forest)\n",
    "# Note: We access the best estimator from our GridSearchCV object 'grid_rf'\n",
    "best_rf = grid_rf.best_estimator_\n",
    "importances = best_rf.feature_importances_\n",
    "feature_names = selected_features.tolist() + list(tfidf.get_feature_names_out())\n",
    "\n",
    "# Verify lengths match before plotting (handling potential mismatch)\n",
    "if len(importances) == len(feature_names):\n",
    "    # Create a DataFrame for better visualization\n",
    "    feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    feat_imp_df = feat_imp_df.sort_values(by='Importance', ascending=False).head(20) # Top 20\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feat_imp_df, palette='viridis')\n",
    "    plt.title('Top 20 Feature Importance (Random Forest)')\n",
    "    plt.show()\n",
    "else:\n",
    "    # Fallback if names don't match (e.g. if using different X_train)\n",
    "    print(f\"Feature count mismatch: Importances={len(importances)}, Names={len(feature_names)}\")\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(importances)\n",
    "    plt.title('Feature Importances (Index)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnvVTiIxBL-C"
   },
   "source": [
    "**Tool:** **Feature Importance (Built-in)**.\n",
    "**Explanation:** Random Forest calculates the average decrease in impurity (variance) each feature contributes.\n",
    "**Finding:**\n",
    "1.  **Votes**: Usually the top predictor (Popularity drives Ratings).\n",
    "2.  **Cost/Log_Cost**: Premium places implies higher quality checks.\n",
    "3.  **Engagement_Score**: Passionate reviews often correlate with extreme (good/bad) ratings.\n",
    "This transparency builds trust with stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyNgTHvd2WFk"
   },
   "source": [
    "## ***8.*** ***Future Work (Optional)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH5McJBi2d8v"
   },
   "source": [
    "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQIANRl32f4J"
   },
   "outputs": [],
   "source": [
    "# Save the File\n",
    "import joblib\n",
    "joblib.dump(grid_rf.best_estimator_, 'zomato_rating_model.pkl')\n",
    "print(\"Model saved as zomato_rating_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW_Lq9qf2h6X"
   },
   "source": [
    "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEXk9ydD2nVC"
   },
   "outputs": [],
   "source": [
    "# Load the File and predict unseen data.\n",
    "loaded_model = joblib.load('zomato_rating_model.pkl')\n",
    "# Predict on first 5 test samples\n",
    "print(\"Predicted samples:\", loaded_model.predict(X_test[:5]))\n",
    "print(\"Actual samples:   \", y_test.iloc[:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Kee-DAl2viO"
   },
   "source": [
    "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCX9965dhzqZ"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjb1IsQkh3yE"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "In this project, we successfully built a Machine Learning pipeline to predict Zomato Restaurant Ratings.\n",
    "1.  **Insights**: Cost and Votes are dominant factors. \"Social Proof\" is real.\n",
    "2.  **Data Quality**: We handled messy text, outliers in Cost, and missing values, proving that *Better Data > Better Algorithms*.\n",
    "3.  **Model**: The **Random Forest** model emerged as the champion, capable of handling the complex, non-linear interactions between cuisine, cost, and user engagement.\n",
    "4.  **Deployment**: The model is serialized and ready for API integration to power real-time recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIfDvo9L0UH2"
   },
   "source": [
    "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vncDsAP0Gaoa",
    "FJNUwmbgGyua",
    "w6K7xa23Elo4",
    "yQaldy8SH6Dl",
    "mDgbUHAGgjLW",
    "O_i_v8NEhb9l",
    "HhfV-JJviCcP",
    "Y3lxredqlCYt",
    "3RnN4peoiCZX",
    "x71ZqKXriCWQ",
    "7hBIi_osiCS2",
    "JlHwYmJAmNHm",
    "35m5QtbWiB9F",
    "PoPl-ycgm1ru",
    "H0kj-8xxnORC",
    "nA9Y7ga8ng1Z",
    "PBTbrJXOngz2",
    "u3PMJOP6ngxN",
    "dauF4eBmngu3",
    "bKJF3rekwFvQ",
    "MSa1f5Uengrz",
    "GF8Ens_Soomf",
    "0wOQAZs5pc--",
    "K5QZ13OEpz2H",
    "lQ7QKXXCp7Bj",
    "448CDAPjqfQr",
    "KSlN3yHqYklG",
    "t6dVpIINYklI",
    "ijmpgYnKYklI",
    "-JiQyfWJYklI",
    "EM7whBJCYoAo",
    "fge-S5ZAYoAp",
    "85gYPyotYoAp",
    "RoGjAbkUYoAp",
    "4Of9eVA-YrdM",
    "iky9q4vBYrdO",
    "F6T5p64dYrdO",
    "y-Ehk30pYrdP",
    "bamQiAODYuh1",
    "QHF8YVU7Yuh3",
    "GwzvFGzlYuh3",
    "qYpmQ266Yuh3",
    "OH-pJp9IphqM",
    "bbFf2-_FphqN",
    "_ouA3fa0phqN",
    "Seke61FWphqN",
    "PIIx-8_IphqN",
    "t27r6nlMphqO",
    "r2jJGEOYphqO",
    "b0JNsNcRphqO",
    "BZR9WyysphqO",
    "jj7wYXLtphqO",
    "eZrbJ2SmphqO",
    "rFu4xreNphqO",
    "YJ55k-q6phqO",
    "gCFgpxoyphqP",
    "OVtJsKN_phqQ",
    "lssrdh5qphqQ",
    "U2RJ9gkRphqQ",
    "1M8mcRywphqQ",
    "tgIPom80phqQ",
    "JMzcOPDDphqR",
    "x-EpHcCOp1ci",
    "X_VqEhTip1ck",
    "8zGJKyg5p1ck",
    "PVzmfK_Ep1ck",
    "n3dbpmDWp1ck",
    "ylSl6qgtp1ck",
    "ZWILFDl5p1ck",
    "M7G43BXep1ck",
    "Ag9LCva-p1cl",
    "E6MkPsBcp1cl",
    "2cELzS2fp1cl",
    "3MPXvC8up1cl",
    "NC_X3p0fY2L0",
    "UV0SzAkaZNRQ",
    "YPEH6qLeZNRQ",
    "q29F0dvdveiT",
    "EXh0U9oCveiU",
    "22aHeOlLveiV",
    "g-ATYxFrGrvw",
    "Yfr_Vlr8HBkt",
    "8yEUt7NnHlrM",
    "tEA2Xm5dHt1r",
    "I79__PHVH19G",
    "Ou-I18pAyIpj",
    "fF3858GYyt-u",
    "4_0_7-oCpUZd",
    "hwyV_J3ipUZe",
    "3yB-zSqbpUZe",
    "dEUvejAfpUZe",
    "Fd15vwWVpUZf",
    "bn_IUdTipZyH",
    "49K5P_iCpZyH",
    "Nff-vKELpZyI",
    "kLW572S8pZyI",
    "dWbDXHzopZyI",
    "yLjJCtPM0KBk",
    "xiyOF9F70UgQ",
    "7wuGOrhz0itI",
    "id1riN9m0vUs",
    "578E2V7j08f6",
    "89xtkJwZ18nB",
    "67NQN5KX2AMe",
    "Iwf50b-R2tYG",
    "GMQiZwjn3iu7",
    "WVIkgGqN3qsr",
    "XkPnILGE3zoT",
    "Hlsf0x5436Go",
    "mT9DMSJo4nBL",
    "c49ITxTc407N",
    "OeJFEK0N496M",
    "9ExmJH0g5HBk",
    "cJNqERVU536h",
    "k5UmGsbsOxih",
    "T0VqWOYE6DLQ",
    "qBMux9mC6MCf",
    "-oLEiFgy-5Pf",
    "C74aWNz2AliB",
    "2DejudWSA-a0",
    "pEMng2IbBLp7",
    "rAdphbQ9Bhjc",
    "TNVZ9zx19K6k",
    "nqoHp30x9hH9",
    "rMDnDkt2B6du",
    "yiiVWRdJDDil",
    "1UUpS68QDMuG",
    "kexQrXU-DjzY",
    "T5CmagL3EC8N",
    "BhH2vgX9EjGr",
    "qjKvONjwE8ra",
    "P1XJ9OREExlT",
    "VFOzZv6IFROw",
    "TIqpNgepFxVj",
    "VfCC591jGiD4",
    "OB4l2ZhMeS1U",
    "ArJBuiUVfxKd",
    "4qY1EAkEfxKe",
    "PiV4Ypx8fxKe",
    "TfvqoZmBfxKf",
    "dJ2tPlVmpsJ0",
    "JWYfwnehpsJ1",
    "-jK_YjpMpsJ2",
    "HAih1iBOpsJ2",
    "zVGeBEFhpsJ2",
    "bmKjuQ-FpsJ3",
    "Fze-IPXLpx6K",
    "7AN1z2sKpx6M",
    "9PIHJqyupx6M",
    "_-qAgymDpx6N",
    "Z-hykwinpx6N",
    "h_CCil-SKHpo",
    "cBFFvTBNJzUa",
    "HvGl1hHyA_VK",
    "EyNgTHvd2WFk",
    "KH5McJBi2d8v",
    "iW_Lq9qf2h6X",
    "-Kee-DAl2viO",
    "gCX9965dhzqZ",
    "gIfDvo9L0UH2"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}